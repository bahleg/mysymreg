{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch \n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from symreg import evaluate_composition, evaluate_tree, SymReg\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_pattern(sequence, pattern):\n",
    "    pattern_str = ''.join(map(str, pattern))\n",
    "    sequence_str = ''.join(map(str, sequence))\n",
    "    return pattern_str in sequence_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nums = []\n",
    "for i in range(16):\n",
    "    all_nums.append(list(map(int, np.binary_repr(i, 4))))\n",
    "all_nums = np.array(all_nums)\n",
    "y1 = np.array([contains_pattern(i, [1, 0, 1]) for i in all_nums])\n",
    "y2 = []\n",
    "for i in all_nums:\n",
    "    cnt = 0\n",
    "    for j in range(0, 2):\n",
    "        if contains_pattern(i[j:j+3], [1, 1, 1]):\n",
    "            cnt+=1\n",
    "    y2.append(cnt)\n",
    "y2 = np.array(y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.5), 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = np.random.RandomState(42)\n",
    "y1_new = list(range(len(all_nums)))\n",
    "while y1[y1_new].mean() != 0.5:\n",
    "    if y1[y1_new].mean()>0.5:\n",
    "        to_add = [i for i in range(len(all_nums)) if y1[i] == 0]\n",
    "    else:\n",
    "        to_add = [i for i in range(len(all_nums)) if y1[i] == 1]\n",
    "    to_add = rs.choice(to_add)\n",
    "    y1_new.append(to_add)\n",
    "y1 = y1[y1_new]\n",
    "y1.mean(), len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = all_nums[y1_new], y1\n",
    "test_dataset = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({np.int64(0): 13, np.int64(1): 13, np.int64(2): 13}), 39)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "rs = np.random.RandomState(42)\n",
    "y2_new = list(range(len(all_nums)))\n",
    "cnt0 = (y2[y2_new]==0).sum()\n",
    "cnt1 = (y2[y2_new]==1).sum()\n",
    "cnt2 = (y2[y2_new]==2).sum()\n",
    "\n",
    "while (cnt0 != cnt1) or (cnt1 != cnt2):\n",
    "    to_add = np.argsort([cnt0, cnt1, cnt2])[0]\n",
    "    to_add = [i for i in range(len(all_nums)) if y2[i] == to_add]\n",
    "    to_add = rs.choice(to_add)\n",
    "    y2_new.append(to_add)\n",
    "    cnt0 = (y2[y2_new]==0).sum()\n",
    "    cnt1 = (y2[y2_new]==1).sum()\n",
    "    cnt2 = (y2[y2_new]==2).sum()\n",
    "\n",
    "\n",
    "y2 = y2[y2_new]\n",
    "Counter(y2), len(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset2 = all_nums[y2_new], y2\n",
    "test_dataset2 = train_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=10.0)\n",
    "model.fit(train_dataset[0], train_dataset[1])\n",
    "print (np.equal(model.predict(test_dataset[0]), test_dataset[1]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1352328030798286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(train_dataset2[0], train_dataset2[1])\n",
    "print (((model.predict(test_dataset2[0]) - test_dataset2[1])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.001234901137650013:  14%|█▍        | 143/1000 [00:35<03:33,  4.00it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m out \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mtensor(train_dataset[\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()(out, torch\u001b[38;5;241m.\u001b[39mtensor(train_dataset[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 35\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m tq\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;28mstr\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem()))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "D = 4\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            1, 1, kernel_size=3)  # 4 фильтра, каждый ищет свой шаблон\n",
    "        self.pool = lambda x: x.max(1).values.max(1).values  #nn.AdaptiveMaxPool2d(1)  # \"обобщает\" по всему пространству\n",
    "        self.fc = nn.Linear(1, 1)  # логрегрессия по 4 признакам\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, D).float()\n",
    "        x = self.conv(x)  # [B, 2, H-2, W-2]\n",
    "        \n",
    "        x = self.pool(x)  # [B, 2, 1, 1]\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # [B, 2]\n",
    "        x = self.fc(x)  # [B, 1]\n",
    "        return x  # [B, 1]\n",
    "\n",
    "epochs = 1000\n",
    "model = SimpleCNN()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "tq = tqdm.tqdm(range(1000))\n",
    "for e in tq:\n",
    "    opt.zero_grad()\n",
    "    out = model(torch.tensor(train_dataset[0])).view(-1)\n",
    "    \n",
    "    loss = torch.nn.BCEWithLogitsLoss()(out, torch.tensor(train_dataset[1]).float())\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    tq.set_description(str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7083)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model( torch.tensor(test_dataset[0]))>0.0\n",
    "torch.eq(out.view(-1), torch.tensor(test_dataset[1]).view(-1)).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6.163609214127064e-05:  73%|███████▎  | 732/1000 [00:02<00:00, 315.00it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m tq \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m tq:\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mtensor(train_dataset2[\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ((out \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_dataset2[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py:435\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    431\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    432\u001b[0m         update_group(g, ng) \u001b[38;5;28;01mfor\u001b[39;00m g, ng \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(groups, saved_groups)]\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__setstate__({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m: state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_groups\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups})\n\u001b[0;32m--> 435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzero_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m, set_to_none: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    436\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the gradients of all optimized :class:`torch.Tensor` s to zero.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m            the step altogether).\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     foreach \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1013:\n",
      "Process ForkPoolWorker-1014:\n",
      "Process ForkPoolWorker-1012:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "D = 4\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            1, 1, kernel_size=3)  # 4 фильтра, каждый ищет свой шаблон\n",
    "        self.pool = lambda x: torch.nn.functional.leaky_relu(x).sum(1).sum(1)  #nn.AdaptiveMaxPool2d(1)  # \"обобщает\" по всему пространству\n",
    "        self.fc = nn.Linear(1, 1)  # логрегрессия по 4 признакам\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, D).float()\n",
    "        x = self.conv(x)  # [B, 2, H-2, W-2]\n",
    "        \n",
    "        x = self.pool(x)  # [B, 2, 1, 1]\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # [B, 2]\n",
    "        x = self.fc(x)  # [B, 1]\n",
    "        return x  # [B, 1]\n",
    "\n",
    "epochs = 1000\n",
    "model = SimpleCNN()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "tq = tqdm.tqdm(range(1000))\n",
    "for e in tq:\n",
    "    opt.zero_grad()\n",
    "    out = model(torch.tensor(train_dataset2[0])).view(-1)\n",
    "    \n",
    "    loss = ((out - torch.tensor(train_dataset2[1]))**2).mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    tq.set_description(str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LinearRegression' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m ((out \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_dataset2[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LinearRegression' object is not callable"
     ]
    }
   ],
   "source": [
    "out = model(torch.tensor(train_dataset2[0])).view(-1)\n",
    "((out - torch.tensor(train_dataset2[1]))**2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63, 4), (63,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = np.vstack([train_dataset[0], train_dataset2[0]])\n",
    "y_all = np.hstack([train_dataset[1], train_dataset2[1]])\n",
    "X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varible_node_in_tree(node):\n",
    "    result = set()\n",
    "    buf = [node]\n",
    "    while len(buf) > 0:\n",
    "        new_node = buf.pop()\n",
    "        if new_node.is_leaf():\n",
    "            result.add(new_node.value)\n",
    "        else:\n",
    "            buf.extend(new_node.children)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from symreg import evaluate_composition, DEFAULT_OPERATIONS\n",
    "\n",
    "import zlib\n",
    "\n",
    "\n",
    "def compress_score(expression_str: str):\n",
    "    compressed = zlib.compress(expression_str.encode('utf-8'))\n",
    "    return len(compressed)\n",
    "\n",
    "\n",
    "def compress_hiddens(composition):\n",
    "    return compress_score(';'.join([\n",
    "        h.polish(DEFAULT_OPERATIONS) for h in composition.children_h]))\n",
    "\n",
    "\n",
    "def acc_loss_fn_min(x, y, ind, variables, pool, OPERATIONS, COMP_SCORE=.001, SPARSE_SCORE=0.0, MAX_VARIABLES = 3):\n",
    "    if COMP_SCORE:\n",
    "        #compl = compress_score(';'.join([str(h) for h in ind.children_h\n",
    "        #                             ]))\n",
    "        compl = compress_hiddens(ind)\n",
    "\n",
    "    else:\n",
    "        compl = 0.0\n",
    "    \n",
    "    if MAX_VARIABLES > 0:\n",
    "        sparse = ([\n",
    "            len([c for c in varible_node_in_tree(h) if c.startswith('x')])\n",
    "            for h in ind.children_h\n",
    "        ])\n",
    "        if max(sparse)>MAX_VARIABLES:\n",
    "            return float('inf'), float('inf'), float('inf'), float('inf'), float('inf')\n",
    "    if SPARSE_SCORE:\n",
    "        sparse = max([\n",
    "            len([c for c in varible_node_in_tree(h) if c.startswith('x')])\n",
    "            for h in ind.children_h\n",
    "        ])\n",
    "    else:\n",
    "        sparse = 0.0\n",
    "\n",
    "    x_train1 = {f'x{i}': x[:24, i] for i in range(4)}\n",
    "    y_train1 = y[:24]\n",
    "\n",
    "    x_train2 = {f'x{i}': x[24:, i] for i in range(4)}\n",
    "    y_train2 = y[24:]\n",
    "\n",
    "    def min_func(x0, var_y):\n",
    "        var_, y_ = var_y\n",
    "        pool_ = {f'p{i}': x0[i] for i in range(len(x0))}\n",
    "\n",
    "        y_pred = evaluate_composition(ind, var_, pool_, OPERATIONS) > 0\n",
    "        errs = -np.equal(y_, y_pred).mean()\n",
    "        return errs\n",
    "\n",
    "    x_opt = minimize(min_func, list(pool.values()), [x_train1, y_train1])\n",
    "    loss1 = min_func(x_opt.x, [x_train1, y_train1])\n",
    "    \"\"\"\n",
    "    hidden1, out1 = evaluate_composition(ind, x_train1, {f'p{i}': x_opt.x[i] for i in range(len(x_opt.x))}, \n",
    "                                             OPERATIONS, 0, True)\n",
    "    hidden1_array = []\n",
    "    for h in hidden1.values():\n",
    "        h = np.array(h)\n",
    "        if len(h.shape) == 0:\n",
    "            h = np.ones(24) * h\n",
    "        hidden1_array.append(h)\n",
    "    hidden1_array = np.array(hidden1_array).T\n",
    "    mi = micd(hidden1_array, y_train1)\n",
    "    \"\"\"\n",
    "\n",
    "    def min_func2(x0, var_y):\n",
    "        var_, y_ = var_y\n",
    "        pool_ = {f'p{i}': x0[i] for i in range(len(x0))}\n",
    "        y_pred = evaluate_composition(ind, var_, pool_, OPERATIONS, g_id=1)\n",
    "        y_pred = np.clip(y_pred, 0, 2)\n",
    "        errs = ((y_ - y_pred)**2).mean() / 2\n",
    "        return errs\n",
    "\n",
    "    x_opt = minimize(min_func2, list(pool.values()), [x_train2, y_train2])\n",
    "\n",
    "    loss2 = 0.0\n",
    "    loss2 = min_func2(x_opt.x, [x_train2, y_train2])\n",
    "    loss = (loss1 + loss2) / 2 + compl * COMP_SCORE + sparse * SPARSE_SCORE\n",
    "\n",
    "    return loss, loss1, loss2, compl, sparse   #, mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gen 0] Expr: \n",
      "h_0 = x2\n",
      "h_1 = x1\n",
      "g_0 = max(mult(p0, max(sub(mult(h1, p1), p1), h1)), max(sub(max(mult(h1, h1), max(h0, h0)), h1), max(mult(sub(p1, p1), max(h1, h0)), sub(add(h1, h0), sub(h1, h1)))))\n",
      "g_1 = max(sub(mult(h1, add(h0, h1)), sub(mult(h1, p1), mult(h0, h1))), mult(mult(max(h0, h1), sub(h1, h0)), h1))\n",
      "[Gen 0] Best errors: (np.float64(-0.24113675213675206), np.float64(-0.6666666666666666), np.float64(0.16239316239316245), 11.000000000000002, 0.0)\n",
      "[Gen 0] Total time: 2.283897876739502\n",
      "[Gen 10] Expr: \n",
      "h_0 = max(x3, p0)\n",
      "h_1 = add(x0, x1)\n",
      "g_0 = mult(mult(mult(max(mult(h0, h0), mult(h0, h0)), p0), add(sub(add(mult(h1, h0), p0), mult(h0, h0)), add(p0, h1))), p0)\n",
      "g_1 = add(h0, add(mult(h0, p0), add(h1, p0)))\n",
      "[Gen 10] Best errors: (np.float64(-0.34118016791468114), np.float64(-0.8333333333333334), np.float64(0.11697299750397107), 17.0, 0.0)\n",
      "[Gen 10] Total time: 25.65399742126465\n",
      "[Gen 20] Expr: \n",
      "h_0 = mult(x2, x0)\n",
      "h_1 = mult(x1, x3)\n",
      "g_0 = max(mult(p0, max(add(h1, h1), h1)), max(sub(max(h1, h0), h1), max(add(mult(max(h1, h0), mult(p0, p0)), mult(max(p0, p0), h0)), sub(mult(p0, p0), add(p1, p1)))))\n",
      "g_1 = max(sub(mult(h1, add(h0, h1)), sub(mult(h1, p1), mult(h0, h1))), mult(mult(max(h0, h1), sub(mult(p0, max(p0, p0)), h0)), h1))\n",
      "[Gen 20] Best errors: (np.float64(-0.40720279720217967), np.float64(-0.9166666666666665), np.float64(0.07226107226230724), 15.0, 0.0)\n",
      "[Gen 20] Total time: 54.17706632614136\n",
      "[Gen 30] Expr: \n",
      "h_0 = mult(x2, x0)\n",
      "h_1 = mult(x1, x3)\n",
      "g_0 = max(mult(p0, max(add(h1, h1), h1)), max(sub(max(h1, h0), h1), max(add(mult(max(h1, h0), mult(p0, p0)), mult(max(p0, p0), h0)), sub(mult(p0, p0), add(p1, p1)))))\n",
      "g_1 = max(sub(mult(h1, add(h0, h1)), sub(mult(h1, p1), mult(h0, h1))), add(mult(h1, p0), mult(add(add(mult(h1, p1), sub(p0, p0)), add(mult(p1, p0), h1)), sub(mult(h0, sub(p0, p1)), add(max(p0, p0), max(p0, h0))))))\n",
      "[Gen 30] Best errors: (np.float64(-0.4242968142967501), np.float64(-0.9166666666666665), np.float64(0.0380730380731664), 15.0, 0.0)\n",
      "[Gen 30] Total time: 88.74389934539795\n",
      "[Gen 40] Expr: \n",
      "h_0 = mult(x2, add(x1, x0))\n",
      "h_1 = mult(x1, add(x3, x2))\n",
      "g_0 = max(mult(p0, max(add(h1, h1), h1)), max(sub(max(h0, h0), h1), max(add(mult(max(h1, h0), mult(p0, p0)), mult(max(p0, p0), h0)), sub(mult(p0, p0), add(p1, p1)))))\n",
      "g_1 = max(sub(mult(h1, add(h0, h1)), sub(mult(h1, p1), mult(h0, h1))), add(mult(h1, p0), mult(add(add(mult(h1, p1), sub(p0, p0)), add(mult(p1, p0), h1)), sub(mult(h0, sub(p0, p1)), add(max(p0, p0), max(p0, h0))))))\n",
      "[Gen 40] Best errors: (np.float64(-0.4553974358974118), np.float64(-0.9583333333333334), np.float64(0.011538461538509846), 18.0, 0.0)\n",
      "[Gen 40] Total time: 130.80369400978088\n",
      "[Gen 50] Expr: \n",
      "h_0 = mult(x2, add(x1, x0))\n",
      "h_1 = mult(x1, add(x3, x2))\n",
      "g_0 = max(mult(p0, max(add(h1, h1), h1)), max(sub(max(h0, h0), h1), max(add(mult(max(h1, h0), mult(p0, p0)), mult(max(p0, p0), h0)), sub(mult(p0, p1), add(p1, p1)))))\n",
      "g_1 = max(sub(sub(add(mult(h0, h1), mult(p0, h1)), p1), sub(mult(h1, p1), mult(h0, h1))), add(mult(h1, p0), mult(add(add(mult(h1, p1), sub(p0, p0)), add(mult(p1, p0), h1)), sub(mult(h0, sub(p0, p1)), add(max(p0, p0), max(p0, h0))))))\n",
      "[Gen 50] Best errors: (np.float64(-0.4611666666666568), np.float64(-0.9583333333333334), np.float64(1.980768140128074e-14), 18.0, 0.0)\n",
      "[Gen 50] Total time: 178.33335757255554\n",
      "[Gen 60] Expr: \n",
      "h_0 = mult(x2, add(x1, mult(x0, p0)))\n",
      "h_1 = mult(x1, add(x3, x2))\n",
      "g_0 = max(mult(p0, max(add(h1, h1), h1)), max(sub(max(h0, h0), h1), max(add(mult(max(h1, h0), mult(p0, p0)), mult(max(p0, p0), h0)), sub(mult(p0, h1), add(p1, p1)))))\n",
      "g_1 = max(sub(mult(h1, add(h0, h1)), sub(mult(h1, p1), mult(h0, h1))), add(mult(h1, p0), mult(add(add(mult(h1, p1), mult(max(p0, h1), p1)), add(mult(p1, p0), h1)), sub(mult(h0, sub(p0, p1)), add(max(p0, p0), max(p0, h0))))))\n",
      "[Gen 60] Best errors: (np.float64(-0.4779999999999999), np.float64(-1.0), np.float64(5.693805940048692e-17), 22.000000000000004, 0.0)\n",
      "[Gen 60] Total time: 226.06669545173645\n",
      "[Gen 70] Expr: \n",
      "h_0 = mult(x2, add(x1, x0))\n",
      "h_1 = mult(x1, add(x3, x2))\n",
      "g_0 = max(mult(p0, max(add(h1, p1), h1)), max(sub(max(h0, h0), add(h1, h1)), max(add(mult(max(h1, h0), mult(p0, p0)), mult(max(p0, p0), h0)), sub(mult(max(p0, h0), add(p1, p0)), add(mult(h0, h0), p1)))))\n",
      "g_1 = max(sub(mult(h1, add(h0, h1)), sub(mult(h1, p1), mult(mult(h0, p0), h1))), add(mult(h1, p0), mult(add(add(mult(h1, add(h1, h1)), mult(max(p0, h1), add(h0, h1))), add(mult(p1, p0), h1)), sub(mult(h0, sub(p0, p1)), add(max(p0, p0), max(p0, h0))))))\n",
      "[Gen 70] Best errors: (np.float64(-0.48199999999999904), np.float64(-1.0), np.float64(1.928370209980782e-15), 18.0, 0.0)\n",
      "[Gen 70] Total time: 272.25866627693176\n",
      "[Gen 80] Expr: \n",
      "h_0 = mult(x2, add(x1, x0))\n",
      "h_1 = mult(x1, add(x3, x2))\n",
      "g_0 = max(mult(p0, max(add(h1, h1), h1)), max(sub(max(h0, h0), add(h1, h1)), max(add(mult(max(h1, h0), mult(p0, p0)), mult(max(p0, p0), h0)), sub(mult(p0, p0), add(p1, p1)))))\n",
      "g_1 = max(sub(mult(h1, add(h0, h1)), sub(mult(h1, p1), mult(mult(h0, p0), h1))), add(h1, mult(add(mult(sub(add(h1, h0), max(p1, h1)), sub(add(p0, h1), p1)), add(mult(p1, p0), h1)), sub(mult(h0, sub(p0, p1)), add(max(p0, p0), max(p0, h0))))))\n",
      "[Gen 80] Best errors: (np.float64(-0.4819999999999991), np.float64(-1.0), np.float64(1.8309054917038564e-15), 18.0, 0.0)\n",
      "[Gen 80] Total time: 326.1353671550751\n",
      "[Gen 90] Expr: \n",
      "h_0 = mult(x2, add(x1, x0))\n",
      "h_1 = mult(x1, add(x3, x2))\n",
      "g_0 = max(mult(p0, max(add(h1, h1), h1)), max(sub(max(h0, h0), add(h1, h1)), max(add(mult(max(h1, h0), mult(p0, p0)), mult(max(p0, p0), h0)), mult(sub(p1, add(h1, p0)), p0))))\n",
      "g_1 = max(sub(mult(h1, add(sub(h0, p0), h1)), sub(mult(h1, p1), mult(mult(h0, p0), h1))), add(h1, mult(add(mult(sub(add(h1, h0), max(p1, h1)), sub(add(p0, h1), p1)), add(mult(p1, p0), h1)), sub(mult(h0, sub(p0, p1)), add(max(p0, p0), max(p0, h0))))))\n",
      "[Gen 90] Best errors: (np.float64(-0.482), np.float64(-1.0), np.float64(4.0036665821172915e-17), 18.0, 0.0)\n",
      "[Gen 90] Total time: 375.05989480018616\n",
      "[Gen 0] Expr: \n",
      "h_0 = x2\n",
      "h_1 = x3\n",
      "g_0 = h1\n",
      "g_1 = max(p0, h0)\n",
      "[Gen 0] Best errors: (np.float64(-0.24861538461538457), np.float64(-0.75), np.float64(0.23076923076923078), 11.000000000000002, 0.0)\n",
      "[Gen 0] Total time: 1.232330560684204\n",
      "[Gen 10] Expr: \n",
      "h_0 = mult(x1, x2)\n",
      "h_1 = x3\n",
      "g_0 = sub(max(p0, h1), max(h0, p0))\n",
      "g_1 = mult(add(p1, h0), max(add(max(p1, h1), add(p0, h0)), sub(sub(h0, h1), max(h1, h0))))\n",
      "[Gen 10] Best errors: (np.float64(-0.3634475524459828), np.float64(-0.8333333333333334), np.float64(0.07843822844136766), 14.0, 0.0)\n",
      "[Gen 10] Total time: 24.1866717338562\n",
      "[Gen 20] Expr: \n",
      "h_0 = mult(x1, x2)\n",
      "h_1 = mult(x3, max(p1, x0))\n",
      "g_0 = sub(max(p0, h1), max(h0, p0))\n",
      "g_1 = mult(add(p1, h0), max(add(max(p1, h1), add(p0, h0)), sub(sub(h0, h1), max(h1, h0))))\n",
      "[Gen 20] Best errors: (np.float64(-0.39049382714879094), np.float64(-0.8333333333333334), np.float64(0.012345679035751483), 20.0, 0.0)\n",
      "[Gen 20] Total time: 49.220866203308105\n",
      "[Gen 30] Expr: \n",
      "h_0 = mult(x1, x2)\n",
      "h_1 = mult(x3, max(mult(p1, x1), x0))\n",
      "g_0 = sub(max(p0, h1), max(h0, p0))\n",
      "g_1 = mult(add(add(h1, h0), h0), max(add(max(p1, h1), add(p0, h0)), sub(sub(h0, h1), max(h1, h0))))\n",
      "[Gen 30] Best errors: (np.float64(-0.4322051279792278), np.float64(-0.9166666666666665), np.float64(0.010256410708211075), 21.0, 0.0)\n",
      "[Gen 30] Total time: 77.69563269615173\n",
      "[Gen 40] Expr: \n",
      "h_0 = mult(x1, x2)\n",
      "h_1 = mult(x3, max(mult(x1, p1), x0))\n",
      "g_0 = sub(max(p0, h1), max(h0, p0))\n",
      "g_1 = mult(add(h0, h0), sub(mult(h1, max(h0, h1)), mult(sub(p1, h0), add(h1, p0))))\n",
      "[Gen 40] Best errors: (np.float64(-0.4322051281966962), np.float64(-0.9166666666666665), np.float64(0.010256410273274225), 21.0, 0.0)\n",
      "[Gen 40] Total time: 114.05649137496948\n",
      "[Gen 50] Expr: \n",
      "h_0 = mult(x1, x2)\n",
      "h_1 = mult(x3, max(mult(x1, p1), x0))\n",
      "g_0 = sub(max(p0, h1), max(h0, p0))\n",
      "g_1 = mult(h0, sub(mult(h1, max(p0, h1)), mult(sub(p1, h0), add(h1, max(h0, p0)))))\n",
      "[Gen 50] Best errors: (np.float64(-0.4322051282051282), np.float64(-0.9166666666666665), np.float64(0.010256410256410258), 21.0, 0.0)\n",
      "[Gen 50] Total time: 147.493403673172\n",
      "[Gen 60] Expr: \n",
      "h_0 = mult(x1, x2)\n",
      "h_1 = mult(x3, max(mult(x1, p1), x0))\n",
      "g_0 = sub(max(p0, h1), max(h0, p0))\n",
      "g_1 = mult(h0, sub(mult(h1, max(p0, h1)), mult(sub(p1, h0), add(h1, max(h0, p0)))))\n",
      "[Gen 60] Best errors: (np.float64(-0.4322051282051282), np.float64(-0.9166666666666665), np.float64(0.010256410256410258), 21.0, 0.0)\n",
      "[Gen 60] Total time: 177.93499183654785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gen 70] Expr: \n",
      "h_0 = mult(x1, x2)\n",
      "h_1 = mult(x3, max(mult(x1, p1), x0))\n",
      "g_0 = sub(max(p0, h1), max(h0, p0))\n",
      "g_1 = mult(h0, sub(mult(h1, max(add(add(p0, h1), h1), h1)), mult(sub(p1, h0), add(h1, max(h0, p0)))))\n",
      "[Gen 70] Best errors: (np.float64(-0.4322051282051282), np.float64(-0.9166666666666665), np.float64(0.010256410256410263), 21.0, 0.0)\n",
      "[Gen 70] Total time: 206.8057520389557\n",
      "[Gen 80] Expr: \n",
      "h_0 = mult(x1, x2)\n",
      "h_1 = mult(x3, max(mult(x1, p1), x0))\n",
      "g_0 = sub(max(p0, h1), max(mult(h0, h1), p0))\n",
      "g_1 = mult(h0, sub(mult(h1, max(add(add(p0, h1), h1), h1)), mult(sub(p1, h0), add(h1, max(h0, p0)))))\n",
      "[Gen 80] Best errors: (np.float64(-0.4322051282051282), np.float64(-0.9166666666666665), np.float64(0.010256410256410263), 21.0, 0.0)\n",
      "[Gen 80] Total time: 238.90065622329712\n",
      "[Gen 90] Expr: \n",
      "h_0 = mult(x1, x2)\n",
      "h_1 = mult(x3, max(mult(x1, p1), x0))\n",
      "g_0 = sub(max(p0, h1), max(h0, p0))\n",
      "g_1 = mult(h0, sub(mult(h1, max(add(add(p0, add(h0, p0)), h1), h1)), mult(sub(p1, h0), add(h1, max(h0, mult(h0, p0))))))\n",
      "[Gen 90] Best errors: (np.float64(-0.4322051282051282), np.float64(-0.9166666666666665), np.float64(0.010256410256410267), 21.0, 0.0)\n",
      "[Gen 90] Total time: 270.45822310447693\n",
      "[Gen 0] Expr: \n",
      "h_0 = x3\n",
      "h_1 = x1\n",
      "g_0 = mult(h0, h0)\n",
      "g_1 = mult(h0, h0)\n",
      "[Gen 0] Best errors: (np.float64(-0.21656410256410255), np.float64(-0.75), np.float64(0.2948717948717948), 11.000000000000002, 0.0)\n",
      "[Gen 0] Total time: 2.3495516777038574\n",
      "[Gen 10] Expr: \n",
      "h_0 = x3\n",
      "h_1 = add(x2, x0)\n",
      "g_0 = mult(h0, max(sub(p1, h0), h1))\n",
      "g_1 = mult(h1, h0)\n",
      "[Gen 10] Best errors: (np.float64(-0.2904871794871795), np.float64(-0.75), np.float64(0.14102564102564102), 14.0, 0.0)\n",
      "[Gen 10] Total time: 15.42555284500122\n",
      "[Gen 20] Expr: \n",
      "h_0 = x3\n",
      "h_1 = mult(x2, x1)\n",
      "g_0 = sub(h0, h1)\n",
      "g_1 = add(h1, mult(mult(h0, p1), sub(p1, p0)))\n",
      "[Gen 20] Best errors: (np.float64(-0.35161355311152154), np.float64(-0.8333333333333334), np.float64(0.10210622711029022), 14.0, 0.0)\n",
      "[Gen 20] Total time: 25.56434655189514\n",
      "[Gen 30] Expr: \n",
      "h_0 = x3\n",
      "h_1 = mult(x2, x1)\n",
      "g_0 = sub(h0, h1)\n",
      "g_1 = add(h1, mult(h1, mult(h0, sub(p0, p1))))\n",
      "[Gen 30] Best errors: (np.float64(-0.36216550116550117), np.float64(-0.8333333333333334), np.float64(0.08100233100233102), 14.0, 0.0)\n",
      "[Gen 30] Total time: 38.69580626487732\n",
      "[Gen 40] Expr: \n",
      "h_0 = x3\n",
      "h_1 = mult(x2, x1)\n",
      "g_0 = sub(h0, h1)\n",
      "g_1 = add(h1, mult(h1, mult(h0, sub(p0, p1))))\n",
      "[Gen 40] Best errors: (np.float64(-0.36216550116550117), np.float64(-0.8333333333333334), np.float64(0.08100233100233102), 14.0, 0.0)\n",
      "[Gen 40] Total time: 50.95866250991821\n",
      "[Gen 50] Expr: \n",
      "h_0 = x3\n",
      "h_1 = mult(x2, x1)\n",
      "g_0 = sub(h0, h1)\n",
      "g_1 = add(h1, add(sub(h1, max(p0, p0)), max(add(p1, h0), p1)))\n",
      "[Gen 50] Best errors: (np.float64(-0.3623057929724597), np.float64(-0.8333333333333334), np.float64(0.08072174738841402), 14.0, 0.0)\n",
      "[Gen 50] Total time: 64.92417097091675\n",
      "[Gen 60] Expr: \n",
      "h_0 = max(x0, mult(x3, x1))\n",
      "h_1 = mult(x2, x1)\n",
      "g_0 = sub(h0, h1)\n",
      "g_1 = add(h1, mult(h1, mult(h0, sub(p0, max(h1, p1)))))\n",
      "[Gen 60] Best errors: (np.float64(-0.3724230769230769), np.float64(-0.875), np.float64(0.09615384615384615), 17.0, 0.0)\n",
      "[Gen 60] Total time: 79.35536217689514\n",
      "[Gen 70] Expr: \n",
      "h_0 = max(mult(x3, x2), mult(x3, x1))\n",
      "h_1 = mult(x2, x1)\n",
      "g_0 = sub(h0, h1)\n",
      "g_1 = add(h1, mult(h1, mult(h0, sub(p0, max(h1, p1)))))\n",
      "[Gen 70] Best errors: (np.float64(-0.3998321678321678), np.float64(-0.9166666666666665), np.float64(0.08100233100233102), 18.0, 0.0)\n",
      "[Gen 70] Total time: 95.63228344917297\n",
      "[Gen 80] Expr: \n",
      "h_0 = max(mult(x2, x3), mult(x3, x1))\n",
      "h_1 = mult(x2, x1)\n",
      "g_0 = sub(h0, h1)\n",
      "g_1 = add(h1, mult(h1, mult(h0, sub(p0, max(h1, p1)))))\n",
      "[Gen 80] Best errors: (np.float64(-0.3998321678321678), np.float64(-0.9166666666666665), np.float64(0.08100233100233102), 18.0, 0.0)\n",
      "[Gen 80] Total time: 111.63103771209717\n",
      "[Gen 90] Expr: \n",
      "h_0 = max(mult(x0, mult(x3, p1)), mult(x3, x1))\n",
      "h_1 = mult(x2, x1)\n",
      "g_0 = sub(h0, h1)\n",
      "g_1 = add(h1, mult(h1, mult(h0, sub(p0, max(h1, p1)))))\n",
      "[Gen 90] Best errors: (np.float64(-0.41204030046455264), np.float64(-0.875), np.float64(0.012919399070894637), 19.0, 0.0)\n",
      "[Gen 90] Total time: 127.86737990379333\n",
      "[Gen 0] Expr: \n",
      "h_0 = mult(x2, x1)\n",
      "h_1 = x0\n",
      "g_0 = mult(h1, h1)\n",
      "g_1 = add(h1, sub(h0, p1))\n",
      "[Gen 0] Best errors: (np.float64(-0.251491452991453), np.float64(-0.625), np.float64(0.09401709401709404), 14.0, 0.0)\n",
      "[Gen 0] Total time: 1.6204895973205566\n",
      "[Gen 10] Expr: \n",
      "h_0 = p0\n",
      "h_1 = add(x2, x1)\n",
      "g_0 = max(sub(p1, max(sub(add(h1, p1), mult(p1, h1)), h1)), mult(h0, add(mult(mult(h1, p0), mult(p0, h1)), max(p1, add(h1, h1)))))\n",
      "g_1 = sub(h1, p0)\n",
      "[Gen 10] Best errors: (np.float64(-0.33929670329670325), np.float64(-0.8333333333333334), np.float64(0.1267399267399268), 14.0, 0.0)\n",
      "[Gen 10] Total time: 17.736862897872925\n",
      "[Gen 20] Expr: \n",
      "h_0 = mult(x2, add(x1, x0))\n",
      "h_1 = x3\n",
      "g_0 = mult(h1, h1)\n",
      "g_1 = add(h1, sub(h0, p1))\n",
      "[Gen 20] Best errors: (np.float64(-0.3518271604938271), np.float64(-0.75), np.float64(0.012345679012345701), 17.0, 0.0)\n",
      "[Gen 20] Total time: 35.950658321380615\n",
      "[Gen 30] Expr: \n",
      "h_0 = mult(x2, add(x1, x0))\n",
      "h_1 = x3\n",
      "g_0 = mult(h1, sub(p1, h0))\n",
      "g_1 = add(h1, sub(h0, p1))\n",
      "[Gen 30] Best errors: (np.float64(-0.37266049382716043), np.float64(-0.7916666666666666), np.float64(0.012345679012345701), 17.0, 0.0)\n",
      "[Gen 30] Total time: 51.19687795639038\n",
      "[Gen 40] Expr: \n",
      "h_0 = mult(x2, add(mult(x1, p1), x0))\n",
      "h_1 = x3\n",
      "g_0 = mult(h1, sub(p1, h0))\n",
      "g_1 = add(h1, sub(h0, p1))\n",
      "[Gen 40] Best errors: (np.float64(-0.39666666666666667), np.float64(-0.8333333333333334), np.float64(1.3989813543133156e-18), 20.0, 0.0)\n",
      "[Gen 40] Total time: 66.07313799858093\n",
      "[Gen 50] Expr: \n",
      "h_0 = mult(x2, add(x1, x0))\n",
      "h_1 = mult(x1, x3)\n",
      "g_0 = sub(h1, mult(h0, sub(h0, p1)))\n",
      "g_1 = add(h1, sub(h0, add(p1, p1)))\n",
      "[Gen 50] Best errors: (np.float64(-0.4403333333333333), np.float64(-0.9166666666666665), np.float64(5.1235986711447425e-17), 18.0, 0.0)\n",
      "[Gen 50] Total time: 81.86288070678711\n",
      "[Gen 60] Expr: \n",
      "h_0 = mult(x2, add(add(x1, x1), x0))\n",
      "h_1 = mult(x1, x3)\n",
      "g_0 = sub(h1, mult(h0, sub(h0, p1)))\n",
      "g_1 = add(h1, sub(h0, add(p1, p1)))\n",
      "[Gen 60] Best errors: (np.float64(-0.48), np.float64(-1.0), np.float64(3.985371207915845e-17), 20.0, 0.0)\n",
      "[Gen 60] Total time: 97.13715672492981\n",
      "[Gen 70] Expr: \n",
      "h_0 = mult(x2, add(add(x1, x1), x0))\n",
      "h_1 = mult(x1, x3)\n",
      "g_0 = sub(h1, mult(h0, sub(h0, p1)))\n",
      "g_1 = add(h1, sub(h0, add(p1, p1)))\n",
      "[Gen 70] Best errors: (np.float64(-0.48), np.float64(-1.0), np.float64(3.985371207915845e-17), 20.0, 0.0)\n",
      "[Gen 70] Total time: 113.0910234451294\n",
      "[Gen 80] Expr: \n",
      "h_0 = mult(x2, add(add(x1, x1), x0))\n",
      "h_1 = mult(x1, x3)\n",
      "g_0 = sub(h1, mult(h0, sub(h0, p1)))\n",
      "g_1 = add(max(h0, h1), sub(h1, add(p1, p1)))\n",
      "[Gen 80] Best errors: (np.float64(-0.48), np.float64(-1.0), np.float64(4.55469189827602e-17), 20.0, 0.0)\n",
      "[Gen 80] Total time: 128.92253279685974\n",
      "[Gen 90] Expr: \n",
      "h_0 = mult(x2, add(add(x1, x1), x0))\n",
      "h_1 = mult(x1, x3)\n",
      "g_0 = sub(h1, mult(h0, sub(h0, p1)))\n",
      "g_1 = add(h1, sub(max(h1, h0), add(p1, p1)))\n",
      "[Gen 90] Best errors: (np.float64(-0.48), np.float64(-1.0), np.float64(4.55469189827602e-17), 20.0, 0.0)\n",
      "[Gen 90] Total time: 144.6431121826172\n",
      "[Gen 0] Expr: \n",
      "h_0 = x3\n",
      "h_1 = x2\n",
      "g_0 = mult(h0, sub(p1, h1))\n",
      "g_1 = add(add(mult(max(h1, p0), p0), add(mult(h0, p1), h1)), mult(h0, add(sub(h0, h0), p0)))\n",
      "[Gen 0] Best errors: (np.float64(-0.27757130312609746), np.float64(-0.75), np.float64(0.17285739374780504), 11.000000000000002, 0.0)\n",
      "[Gen 0] Total time: 1.6480369567871094\n",
      "[Gen 10] Expr: \n",
      "h_0 = add(x1, mult(x0, x2))\n",
      "h_1 = x3\n",
      "g_0 = mult(add(add(mult(add(h0, p0), add(p0, h0)), p0), p0), mult(mult(p0, h0), mult(h1, max(max(h1, h0), mult(h0, h1)))))\n",
      "g_1 = mult(h0, h1)\n",
      "[Gen 10] Best errors: (np.float64(-0.3964615384615384), np.float64(-0.9166666666666665), np.float64(0.08974358974358974), 17.0, 0.0)\n",
      "[Gen 10] Total time: 23.105340480804443\n",
      "[Gen 20] Expr: \n",
      "h_0 = add(x1, mult(x0, x2))\n",
      "h_1 = add(x3, x2)\n",
      "g_0 = mult(add(add(mult(add(h0, p0), add(p0, h0)), p0), p0), mult(mult(p0, h0), mult(h1, max(max(h1, h0), h0))))\n",
      "g_1 = mult(add(p0, h0), h1)\n",
      "[Gen 20] Best errors: (np.float64(-0.42591025641025637), np.float64(-0.9166666666666665), np.float64(0.028846153846153886), 18.0, 0.0)\n",
      "[Gen 20] Total time: 48.526580572128296\n",
      "[Gen 30] Expr: \n",
      "h_0 = add(x1, mult(add(x1, x0), x2))\n",
      "h_1 = x3\n",
      "g_0 = mult(add(add(mult(add(h0, p0), add(p0, h0)), p0), p0), mult(mult(p0, h0), mult(h1, max(max(h1, mult(p1, h0)), mult(h0, h1)))))\n",
      "g_1 = sub(sub(h0, p1), mult(p0, h1))\n",
      "[Gen 30] Best errors: (np.float64(-0.46116666663120265), np.float64(-0.9583333333333334), np.float64(7.092807056440023e-11), 18.0, 0.0)\n",
      "[Gen 30] Total time: 76.33205962181091\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "reduced_operations = {\n",
    "    'add': (operator.add, 2),\n",
    "    'sub': (operator.sub, 2),\n",
    "    'mult': (operator.mul, 2),\n",
    "    'max': (np.maximum, 2)\n",
    "}\n",
    "import time\n",
    "time_s = time.time()\n",
    "run_num = 20\n",
    "#gens = []\n",
    "for r in range(run_num):\n",
    "    symreg = SymReg(acc_loss_fn_min,\n",
    "                    X_all,\n",
    "                    y_all,\n",
    "                    4,\n",
    "                    2,\n",
    "                    2,\n",
    "                    2,\n",
    "                    1000,\n",
    "                    proc_num = 8,\n",
    "                    operations=reduced_operations,\n",
    "                    mutate_params=False,\n",
    "                    max_depth=5)\n",
    "    gens.append(symreg.fit(100, 10, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad = 0\n",
    "for g in gens[-20:]:\n",
    "    if len({'x0', 'x3'} & varible_node_in_tree(g.children_h[0]))==2 or len({'x0', 'x3'} & varible_node_in_tree(g.children_h[1]))==2:\n",
    "        bad+=1\n",
    "bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (np.float64(-0.482), np.float64(-1.0), np.float64(5.533905632126493e-17), 18.0, 0.0)\n",
      "1 (np.float64(-0.4322051282051282), np.float64(-0.9166666666666665), np.float64(0.010256410256410272), 21.0, 0.0)\n",
      "2 (np.float64(-0.43287363379788596), np.float64(-0.9166666666666665), np.float64(0.012919399070894637), 19.0, 0.0)\n",
      "3 (np.float64(-0.48), np.float64(-1.0), np.float64(5.266435960717949e-17), 20.0, 0.0)\n",
      "4 (np.float64(-0.481), np.float64(-1.0), np.float64(5.075596234506717e-17), 19.0, 0.0)\n",
      "5 (np.float64(-0.4237254901960784), np.float64(-0.9166666666666665), np.float64(0.0392156862745098), 15.0, 0.0)\n",
      "6 (np.float64(-0.4195), np.float64(-0.875), np.float64(3.919701213340918e-17), 18.0, 0.0)\n",
      "7 (np.float64(-0.483), np.float64(-1.0), np.float64(5.4856348365035943e-17), 17.0, 0.0)\n",
      "8 (np.float64(-0.4393333333333333), np.float64(-0.9166666666666665), np.float64(4.463783359904153e-19), 19.0, 0.0)\n",
      "9 (np.float64(-0.4352051282051282), np.float64(-0.9166666666666665), np.float64(0.010256410256410263), 18.0, 0.0)\n",
      "10 (np.float64(-0.4095), np.float64(-0.875), np.float64(5.2016119275012544e-23), 28.0, 0.0)\n",
      "11 (np.float64(-0.48), np.float64(-1.0), np.float64(3.70069576996726e-17), 20.0, 0.0)\n",
      "12 (np.float64(-0.482), np.float64(-1.0), np.float64(3.465047227834868e-17), 18.0, 0.0)\n",
      "13 (np.float64(-0.474047619047619), np.float64(-1.0), np.float64(0.011904761904761946), 20.0, 0.0)\n",
      "14 (np.float64(-0.46216666666666667), np.float64(-0.9583333333333334), np.float64(4.638152861108527e-17), 17.0, 0.0)\n",
      "15 (np.float64(-0.45816666666666667), np.float64(-0.9583333333333334), np.float64(4.9658942302189426e-17), 21.0, 0.0)\n",
      "16 (np.float64(-0.481), np.float64(-1.0), np.float64(4.028936367977536e-17), 19.0, 0.0)\n",
      "17 (np.float64(-0.48), np.float64(-1.0), np.float64(2.155379755191306e-17), 20.0, 0.0)\n",
      "18 (np.float64(-0.477), np.float64(-1.0), np.float64(8.745897524716403e-18), 23.0, 0.0)\n",
      "19 (np.float64(-0.4041142191142191), np.float64(-0.9166666666666665), np.float64(0.07843822843822851), 15.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "for g_id, g in enumerate(gens[-20:]):\n",
    "    print (g_id, g.fitness.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "h_0 = x3\n",
      "h_1 = add(sub(x1, x3), x2)\n",
      "g_0 = sub(mult(h0, sub(p0, h0)), mult(mult(h1, p1), max(h1, h1)))\n",
      "g_1 = sub(max(p0, add(mult(p0, h0), sub(add(sub(h1, h1), add(h1, h1)), sub(h1, h0)))), sub(sub(h0, sub(mult(p1, h1), sub(h1, p1))), sub(sub(sub(h0, p1), add(h1, h1)), max(p1, h0))))\n"
     ]
    }
   ],
   "source": [
    "print(gens[-20:][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import re\n",
    "\n",
    "# Создаем переменные\n",
    "symbols = ['x0', 'x1', 'x2', 'x3', 'p1']\n",
    "locals_dict = {s: sp.Symbol(s) for s in symbols}\n",
    "\n",
    "# Преобразование функции по имени\n",
    "def apply_func(func, args):\n",
    "    if func == 'add':\n",
    "        return args[0] + args[1]\n",
    "    elif func == 'sub':\n",
    "        return args[0] - args[1]\n",
    "    elif func == 'mult':\n",
    "        return args[0] * args[1]\n",
    "    elif func == 'div':\n",
    "        return args[0] / args[1]\n",
    "    elif func == 'max':\n",
    "        return sp.Max(*args)\n",
    "    elif func == 'min':\n",
    "        return sp.Min(*args)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown function: {func}\")\n",
    "\n",
    "# Парсер\n",
    "def parse_expression(expr_str):\n",
    "    # Удалим пробелы\n",
    "    expr_str = expr_str.replace(' ', '')\n",
    "    \n",
    "    def parse(tokens):\n",
    "        token = tokens.pop(0)\n",
    "        if token in locals_dict:\n",
    "            return locals_dict[token]\n",
    "        elif re.match(r'^-?\\d+(\\.\\d+)?$', token):\n",
    "            return sp.sympify(token)\n",
    "        elif token in {'add', 'sub', 'mult', 'div', 'max', 'min'}:\n",
    "            assert tokens.pop(0) == '(', \"Expected '('\"\n",
    "            args = []\n",
    "            depth = 1\n",
    "            current = ''\n",
    "            while depth > 0:\n",
    "                t = tokens.pop(0)\n",
    "                if t == '(':\n",
    "                    depth += 1\n",
    "                    current += t\n",
    "                elif t == ')':\n",
    "                    depth -= 1\n",
    "                    if depth == 0:\n",
    "                        if current:\n",
    "                            args.append(parse(tokenize(current)))\n",
    "                        break\n",
    "                    else:\n",
    "                        current += t\n",
    "                elif t == ',' and depth == 1:\n",
    "                    args.append(parse(tokenize(current)))\n",
    "                    current = ''\n",
    "                else:\n",
    "                    current += t\n",
    "            return apply_func(token, args)\n",
    "        else:\n",
    "            return sp.Symbol(token)\n",
    "    return parse(tokenize(expr_str))\n",
    "\n",
    "# Токенизатор простого вида (можно заменить на парсер-парсер)\n",
    "def tokenize(s):\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        if s[i] in '(),':\n",
    "            tokens.append(s[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            j = i\n",
    "            while i < len(s) and s[i] not in '(),':\n",
    "                i += 1\n",
    "            tokens.append(s[j:i])\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Пример\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[43mgens\u001b[49m[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(gen\u001b[38;5;241m.\u001b[39mchildren_h[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m h0 \u001b[38;5;241m=\u001b[39m parse_expression(expr)\u001b[38;5;241m.\u001b[39msimplify()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gens' is not defined"
     ]
    }
   ],
   "source": [
    "# Пример\n",
    "gen = gens[2]\n",
    "\n",
    "expr = str(gen.children_h[0])\n",
    "h0 = parse_expression(expr).simplify()\n",
    "\n",
    "expr = str(gen.children_h[1])\n",
    "h1 = parse_expression(expr).simplify()\n",
    "\n",
    "expr = str(gen.children_g[0])\n",
    "g0 = parse_expression(expr)\n",
    "\n",
    "\n",
    "expr = str(gen.children_g[1])\n",
    "g1 = parse_expression(expr)\n",
    "\n",
    "\n",
    "print(h0)\n",
    "print(h1)\n",
    "g0 = (g0.subs({'h0': h0, 'h1': h1})).simplify()\n",
    "g1 = (g1.subs({'h0': h0, 'h1': h1})).simplify()\n",
    "print(g0)\n",
    "print (g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({p0*x1 - p0 - p1 + 3*x1 + 3*x2*(Max(p0, x0) - Max(p0, x2)) + 2*x2 + x3 + Max(p1, -x1 - x2*(Max(p0, x0) - Max(p0, x2)) - x2) - Max(p1, p0 + x1 + x2*(Max(p0, x0) - Max(p0, x2)) + x2)})"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import symbols, sin, log, Add, Max\n",
    "Max.make_args(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "h_0 = add(x0, add(mult(p0, x1), x2))\n",
      "h_1 = add(x1, add(mult(p0, x2), x3))\n",
      "g_0 = add(max(h0, h1), p0)\n"
     ]
    }
   ],
   "source": [
    "from symreg import Node, Composition, DEFAULT_OPERATIONS\n",
    "x1 = Node('x0')\n",
    "x2 = Node('x1')\n",
    "x3 = Node('x2')\n",
    "x4 = Node('x3')\n",
    "p0 = Node('p0')\n",
    "p1 = Node('p1')\n",
    "mx1 = Node('mult', [p0, x2])\n",
    "mx2 = Node('mult', [p0, x3])\n",
    "\n",
    "mx11 = Node('add', [mx1, x3])\n",
    "mx22 = Node('add', [mx2, x4])\n",
    "\n",
    "h1 = Node('add', [x1, mx11])\n",
    "h2 = Node('add', [x2, mx22])\n",
    "h1_ = Node('h0')\n",
    "h2_ = Node('h1')\n",
    "g0 = Node('max', [h1_, h2_])\n",
    "comp = Composition([h1, h2], [Node('add', [g0, p0])])\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add(x0, add(mult(p0, x1), x2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AX,ACP,X,X'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.equal(np.round(evaluate_composition(comp, {f'x{i}':X_all[:24,i] for i in range(4)}, {'p0':  -1.0}, DEFAULT_OPERATIONS)) > 0, y_all[:24])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_hiddens(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micd(hiddens, Y_all), compress_score(str(h1)+';'+str(h2)), np.corrcoef(hiddens.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mi(h, y):\n",
    "    mi = 0.0\n",
    "    for _ in range(100):\n",
    "        # Случайная проекция (например, гауссовская)\n",
    "        P = np.random.randn(h.shape[1], 1)  # Проекция на 1 признак\n",
    "\n",
    "        # Вычисление ковариации между x и проекцией y\n",
    "        cov_matrix = np.cov(h @ P, y.reshape(-1, 1).T, rowvar=False)\n",
    "        mi += cov_matrix[0, 1]**2\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1, 1, 3], expected input[1, 100, 4] to have 1 channels, but got 100 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m micd\n\u001b[0;32m----> 2\u001b[0m conv_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m conv_out\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      4\u001b[0m simple_mi(conv_out\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_dataset[\u001b[38;5;241m1\u001b[39m]), micd(conv_out\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), train_dataset[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 1, 3], expected input[1, 100, 4] to have 1 channels, but got 100 channels instead"
     ]
    }
   ],
   "source": [
    "from mi import micd\n",
    "conv_out = model.conv(train_dataset[0]).view(100, -1)\n",
    "conv_out.shape\n",
    "simple_mi(conv_out.detach().numpy(), train_dataset[1]), micd(conv_out.detach().numpy(), train_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "from onetask_hid_pool import evaluate_tree\n",
    "\n",
    "\n",
    "def discretize(vec, bins=10):\n",
    "    return np.digitize(vec, bins=np.histogram_bin_edges(vec, bins=bins))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def acc_loss_fn(x, y, ind, variables, pool, OPERATIONS):\n",
    "    new_vars = []\n",
    "\n",
    "    mi = 0.0\n",
    "\n",
    "    for h_id, h in enumerate(ind.children_h):\n",
    "        res = np.array(evaluate_tree(h, variables | pool, OPERATIONS))\n",
    "        if len(res.shape) == 0:\n",
    "            res = np.ones(x.shape[0]) * res\n",
    "        new_vars.append(res)\n",
    "\n",
    "    new_vars = np.array(new_vars).T\n",
    "    try:\n",
    "        mi = float(micd(new_vars, y))  #simple_mi(new_vars, y)\n",
    "    except:\n",
    "        mi = 10000000.0\n",
    "\n",
    "    y_pred = evaluate_composition(ind, variables, pool, OPERATIONS) > 0\n",
    "    result = np.equal(y, y_pred).mean()\n",
    "    loss = result\n",
    "    compl = compress_score(';'.join([str(h) for h in ind.children_h\n",
    "                                     ]))  #composition_node_num(ind)\n",
    "\n",
    "    corr = abs(np.corrcoef(new_vars.T))\n",
    "    corr[corr != corr] = 1.0\n",
    "    corr = corr.mean()\n",
    "    return -loss + compl * 0.00001 + mi * 0.001 + corr * 1.0, loss, compl, mi, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_loss_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m\n\u001b[1;32m      2\u001b[0m DEFAULT_OPERATIONS \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m: (operator\u001b[38;5;241m.\u001b[39madd, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub\u001b[39m\u001b[38;5;124m'\u001b[39m: (operator\u001b[38;5;241m.\u001b[39msub, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmult\u001b[39m\u001b[38;5;124m'\u001b[39m: (operator\u001b[38;5;241m.\u001b[39mmul, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: (np\u001b[38;5;241m.\u001b[39mmaximum, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m best, trees \u001b[38;5;241m=\u001b[39m run_deap_gp(\u001b[43macc_loss_fn\u001b[49m,\n\u001b[1;32m     11\u001b[0m                           \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     12\u001b[0m                           \u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     13\u001b[0m                           \u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     14\u001b[0m                           X_all,\n\u001b[1;32m     15\u001b[0m                           Y_all,\n\u001b[1;32m     16\u001b[0m                           generations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     17\u001b[0m                           raise_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m                           log_perf_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     19\u001b[0m                           log_models_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     20\u001b[0m                           OPERATIONS\u001b[38;5;241m=\u001b[39mDEFAULT_OPERATIONS\n\u001b[1;32m     21\u001b[0m                           )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest expression:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_loss_fn' is not defined"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "DEFAULT_OPERATIONS = {\n",
    "    'add': (operator.add, 2),\n",
    "    'sub': (operator.sub, 2),\n",
    "    'mult': (operator.mul, 2),\n",
    "    'max': (np.maximum, 2)\n",
    "}\n",
    "\n",
    "\n",
    "best, trees = run_deap_gp(acc_loss_fn,\n",
    "                          4,\n",
    "                          16,\n",
    "                          16,\n",
    "                          X_all,\n",
    "                          Y_all,\n",
    "                          generations=1000,\n",
    "                          raise_error=True,\n",
    "                          log_perf_every=10,\n",
    "                          log_models_every=-1,\n",
    "                          OPERATIONS=DEFAULT_OPERATIONS\n",
    "                          )\n",
    "print(\"Best expression:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7d06b8239210>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = np.zeros((6, 6))\n",
    "i = np.unravel_index([12, 15, 22, 24, 35], [6, 6])\n",
    "mat[i] = 1\n",
    "plt.matshow(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def acc_loss_fn_min(x, y, ind, variables, pool, OPERATIONS):\n",
    "\n",
    "    def min_func(x0):\n",
    "        \n",
    "        pool_ = {f'p{i}': x0[i] for i in range(len(x0))}\n",
    "        y_pred = evaluate_composition(ind, variables, pool_, OPERATIONS) > 0\n",
    "        result = np.equal(y, y_pred).mean()\n",
    "        return result\n",
    "\n",
    "    x_opt = minimize(min_func, list(pool.values()))\n",
    "    loss = min_func(x_opt.x)\n",
    "    compl = composition_node_num(ind)\n",
    "    return -loss + compl * 1e-10, loss, compl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gen 0] Best errors: (-0.4999999857, 0.5, 143.0)\n",
      "[Gen 100] Best errors: (-0.5899999949, 0.59, 51.0)\n",
      "[Gen 200] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 300] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 400] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 500] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 600] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 700] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 800] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 900] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1000] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1100] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1200] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1300] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1400] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1500] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1600] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1700] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1800] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 1900] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 2000] Best errors: (-0.6099999956, 0.61, 44.00000000000001)\n",
      "[Gen 2100] Best errors: (-0.6149999947, 0.6150000000000001, 53.0)\n",
      "[Gen 2200] Best errors: (-0.6149999948, 0.6150000000000001, 52.0)\n",
      "[Gen 2300] Best errors: (-0.6199999947, 0.62, 53.0)\n",
      "[Gen 2400] Best errors: (-0.6199999947, 0.62, 53.0)\n",
      "[Gen 2500] Best errors: (-0.6199999947, 0.62, 53.0)\n",
      "[Gen 2600] Best errors: (-0.6199999947, 0.62, 53.0)\n",
      "[Gen 2700] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 2800] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 2900] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3000] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3100] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3200] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3300] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3400] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3500] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3600] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3700] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3800] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 3900] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4000] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4100] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4200] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4300] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4400] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4500] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4600] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4700] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4800] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 4900] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5000] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5100] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5200] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5300] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5400] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5500] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5600] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5700] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5800] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 5900] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6000] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6100] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6200] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6300] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6400] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6500] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6600] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6700] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6800] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 6900] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 7000] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 7100] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 7200] Best errors: (-0.6249999947, 0.625, 53.0)\n",
      "[Gen 7300] Best errors: (-0.6349999946, 0.635, 54.0)\n",
      "[Gen 7400] Best errors: (-0.6349999946, 0.635, 54.0)\n",
      "[Gen 7500] Best errors: (-0.6349999946, 0.635, 54.0)\n",
      "[Gen 7600] Best errors: (-0.6349999946, 0.635, 54.0)\n",
      "[Gen 7700] Best errors: (-0.6349999946, 0.635, 54.0)\n",
      "[Gen 7800] Best errors: (-0.6399999938, 0.64, 62.0)\n",
      "[Gen 7900] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n",
      "[Gen 8000] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n",
      "[Gen 8100] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n",
      "[Gen 8200] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n",
      "[Gen 8300] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n",
      "[Gen 8400] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n",
      "[Gen 8500] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n",
      "[Gen 8600] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n",
      "[Gen 8700] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n",
      "[Gen 8800] Best errors: (-0.6449999938000001, 0.6450000000000001, 62.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best, trees \u001b[38;5;241m=\u001b[39m \u001b[43mrun_deap_gp\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc_loss_fn_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m36\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mY_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mlog_perf_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mlog_models_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmutate_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m                          \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest expression:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best)\n",
      "File \u001b[0;32m~/reps/mysymreg/onetask_hid_pool.py:204\u001b[0m, in \u001b[0;36mrun_deap_gp\u001b[0;34m(loss_fn, comp_num, hidden_num, param_num, x, y, init_pop, generations, pmut, weights, OPERATIONS, raise_error, weight_err_eps, log_models_every, log_perf_every, elite_part, mutate_params, current_gen)\u001b[0m\n\u001b[1;32m    201\u001b[0m pop \u001b[38;5;241m=\u001b[39m toolbox\u001b[38;5;241m.\u001b[39mpopulation(n\u001b[38;5;241m=\u001b[39minit_pop)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(generations):\n\u001b[0;32m--> 204\u001b[0m     offspring \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvarAnd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoolbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcxpb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutpb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpmut\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m offspring:\n\u001b[1;32m    207\u001b[0m         ind\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m toolbox\u001b[38;5;241m.\u001b[39mevaluate(ind)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/deap/algorithms.py:79\u001b[0m, in \u001b[0;36mvarAnd\u001b[0;34m(population, toolbox, cxpb, mutpb)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(offspring)):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m mutpb:\n\u001b[0;32m---> 79\u001b[0m         offspring[i], \u001b[38;5;241m=\u001b[39m \u001b[43mtoolbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutate\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffspring\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m offspring[i]\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m offspring\n",
      "File \u001b[0;32m~/reps/mysymreg/onetask_hid_pool.py:151\u001b[0m, in \u001b[0;36mrun_deap_gp.<locals>.mutate\u001b[0;34m(ind)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmutate\u001b[39m(ind):\n\u001b[0;32m--> 151\u001b[0m     ind_copy \u001b[38;5;241m=\u001b[39m \u001b[43mind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     element_id \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, hidden_num)\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m element_id \u001b[38;5;241m<\u001b[39m hidden_num:\n",
      "File \u001b[0;32m~/reps/mysymreg/onetask_hid_pool.py:25\u001b[0m, in \u001b[0;36mComposition.copy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "    \u001b[0;31m[... skipping similar frames: deepcopy at line 146 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "    \u001b[0;31m[... skipping similar frames: deepcopy at line 146 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "    \u001b[0;31m[... skipping similar frames: deepcopy at line 146 (8 times), deepcopy at line 172 (5 times), _deepcopy_dict at line 231 (4 times), _deepcopy_list at line 206 (4 times), _reconstruct at line 271 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "    \u001b[0;31m[... skipping similar frames: deepcopy at line 146 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:275\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    273\u001b[0m     y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(state) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    276\u001b[0m         state, slotstate \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best, trees = run_deap_gp(acc_loss_fn_min,\n",
    "                          2,\n",
    "                          36,\n",
    "                          16,\n",
    "                          X_all,\n",
    "                          Y_all,\n",
    "                          generations=10000,\n",
    "                          raise_error=True,\n",
    "                          log_perf_every=100,\n",
    "                          log_models_every=-1,\n",
    "                          mutate_params=False\n",
    "                          \n",
    "                          )\n",
    "print(\"Best expression:\", best)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
